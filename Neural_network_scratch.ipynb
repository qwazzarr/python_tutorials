{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.8    1.21   2.385]\n",
      " [ 8.9   -1.81   0.2  ]\n",
      " [ 1.41   1.051  0.026]] [[-2.1744   3.21425  1.19065]\n",
      " [ 0.707    0.6828   4.5213 ]\n",
      " [-1.39594  1.9477  -0.14521]]\n"
     ]
    }
   ],
   "source": [
    "#CODING NEURON\n",
    "inputs = [[1.0,2.0,3.0,2.5],\n",
    "          [2.0,5.0,-1.0,2.0],\n",
    "          [-1.5,2.7,3.3,-0.8]]\n",
    "weights = [ [0.2,0.8,-0.5,1.0],\n",
    "            [0.5,-0.91,0.26,-0.5],\n",
    "            [-0.26,-0.27,0.17,0.87],]\n",
    "biases2 = [-1,2,-0.5]\n",
    "biases = [2.0,3.0,0.5]\n",
    "weights2 = [ [0.1,-0.14,0.5],\n",
    "            [-0.5,0.12,-0.33],\n",
    "            [-0.44,0.73,-0.13],]\n",
    "layer1_outputs = np.dot(inputs,np.array(weights).T)+biases\n",
    "\n",
    "layer2_outputs = np.dot(layer1_outputs,np.array(weights2))+biases2\n",
    "\n",
    "print(layer1_outputs,  layer2_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Layer_Dense:\n",
    "    def __init__(self,n_inputs,n_neurons):\n",
    "        self.weights = 0.10 *np.random.randn(n_inputs,n_neurons)\n",
    "        self.biases = np.zeros((1,n_neurons))\n",
    "    def forward(self,inputs):\n",
    "        self.output = np.dot(inputs,self.weights)+self.biases\n",
    "\n",
    "class Activation_Relu:\n",
    "    def forward(self,inputs):\n",
    "        self.output = np.maximum(0,inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nnfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnfs.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnfs.datasets import spiral_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1],c=y, cmap=\"brg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(points, classes):\n",
    "    X = np.zeros((points*classes, 2))\n",
    "    y = np.zeros(points*classes, dtype='uint8')\n",
    "    for class_number in range(classes):\n",
    "        ix = range(points*class_number, points*(class_number+1))\n",
    "        r = np.linspace(0.0, 1, points)  # radius\n",
    "        t = np.linspace(class_number*4, (class_number+1)*4, points) + np.random.randn(points)*0.2\n",
    "        X[ix] = np.c_[r*np.sin(t*2.5), r*np.cos(t*2.5)]\n",
    "        y[ix] = class_number\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_Softmax:\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        # get unnormalized probabilities\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "        # normalize them for each sample\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "\n",
    "        self.output = probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.34\n",
      "1.0984450276692708\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X, y = create_data(100,3)\n",
    "layer1 = Layer_Dense(2,3)\n",
    "layer2 = Layer_Dense(3,3)\n",
    "activation1 = Activation_Relu()\n",
    "layer1.forward(X)\n",
    "activation1.forward(layer1.output)\n",
    "activation2 = Activation_Softmax()\n",
    "layer2.forward(activation1.output)\n",
    "activation2.forward(layer2.output)\n",
    "loss_function = Loss_CategoricalCrossentropy()\n",
    "loss = loss_function.forward(activation2.output, y)\n",
    "# Calculate accuracy from output of activation2 and targets\n",
    "predictions = np.argmax(activation2.output, axis=1)  # calculate values along first axis\n",
    "accuracy = np.mean(predictions==y)\n",
    "\n",
    "# Print accuracy\n",
    "print('acc:', accuracy)\n",
    "print(loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=uint8)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_CategoricalCrossentropy:\n",
    "\n",
    "    def forward(self, y_pred, y_true):  # y_true should be in format [1,0,0] ( 1 for right class , 0 for wrong ones)\n",
    "\n",
    "        # Number of samples in a batch\n",
    "        samples = len(y_pred)\n",
    "\n",
    "        # Probabilities for target values\n",
    "        y_pred = y_pred[range(samples), y_true]\n",
    "\n",
    "        # Losses\n",
    "        negative_log_likelihoods = -np.log(y_pred)\n",
    "\n",
    "        # Average loss\n",
    "        data_loss = np.sum(negative_log_likelihoods) / samples # Mean\n",
    "        return data_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.35667494393873245"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.log(0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New set of weights found, iteration: 0 loss: 1.0983352661132812 acc: 0.38\n",
      "New set of weights found, iteration: 47 loss: 1.0983258056640626 acc: 0.3566666666666667\n",
      "New set of weights found, iteration: 758 loss: 1.0982578531901042 acc: 0.33\n",
      "New set of weights found, iteration: 1089 loss: 1.0981203206380208 acc: 0.38\n",
      "New set of weights found, iteration: 4352 loss: 1.098033650716146 acc: 0.3433333333333333\n",
      "New set of weights found, iteration: 7101 loss: 1.0978054809570312 acc: 0.34\n"
     ]
    }
   ],
   "source": [
    "#Random optimisation ( full random weights and biases)\n",
    " #Helper variables\n",
    "lowest_loss = 9999999  # some initial value\n",
    "best_layer1_weights = layer1.weights\n",
    "best_layer1_biases = layer1.biases\n",
    "best_layer2_weights = layer2.weights\n",
    "best_layer2_biases = layer2.biases\n",
    "# Random iteration with calculating the least loss\n",
    "for iteration in range(100000):\n",
    "\n",
    "    # Generate a new set of weights for iteration\n",
    "    layer1.weights = 0.05 * np.random.randn(2, 3)\n",
    "    layer1.biases = 0.05 * np.random.randn(1, 3)\n",
    "    layer2.weights = 0.05 * np.random.randn(3, 3)\n",
    "    layer2.biases = 0.05 * np.random.randn(1, 3)\n",
    "\n",
    "    # Make a forward pass of the training data through this layer\n",
    "    layer1.forward(X)\n",
    "    activation1.forward(layer1.output)\n",
    "    layer2.forward(activation1.output)\n",
    "    activation2.forward(layer2.output)\n",
    "    # Calculate loss (from activation output, softmax activation here) and accuracy\n",
    "    loss = loss_function.forward(activation2.output, y)\n",
    "    predictions = np.argmax(activation2.output, axis=1)  # calculate values along first axis\n",
    "    accuracy = np.mean(predictions==y)\n",
    "\n",
    "    # If loss is smaller - print and save weights and biases aside\n",
    "    if loss < lowest_loss:\n",
    "        print('New set of weights found, iteration:', iteration, 'loss:', loss, 'acc:', accuracy)\n",
    "        best_layer1_weights = layer1.weights\n",
    "        best_layer1_biases = layer1.biases\n",
    "        best_layer2_weights = layer2.weights\n",
    "        best_layer2_biases = layer2.biases\n",
    "        lowest_loss = loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: RuntimeWarning: divide by zero encountered in log\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New set of weights found, iteration: 901 loss: 21.573196614583335 acc: 0.31333333333333335\n",
      "New set of weights found, iteration: 902 loss: 21.547106119791668 acc: 0.31333333333333335\n",
      "New set of weights found, iteration: 903 loss: 21.525667317708333 acc: 0.31\n",
      "New set of weights found, iteration: 904 loss: 21.389269205729168 acc: 0.31333333333333335\n",
      "New set of weights found, iteration: 905 loss: 21.060724283854167 acc: 0.30666666666666664\n",
      "New set of weights found, iteration: 941 loss: 20.90427083333333 acc: 0.30333333333333334\n",
      "New set of weights found, iteration: 942 loss: 20.617693684895833 acc: 0.31\n",
      "New set of weights found, iteration: 944 loss: 20.17513671875 acc: 0.3\n",
      "New set of weights found, iteration: 945 loss: 19.99554524739583 acc: 0.3\n",
      "New set of weights found, iteration: 965 loss: 19.330680338541665 acc: 0.2833333333333333\n",
      "New set of weights found, iteration: 968 loss: 19.325986328125 acc: 0.2833333333333333\n",
      "New set of weights found, iteration: 969 loss: 19.040247395833333 acc: 0.28\n",
      "New set of weights found, iteration: 1149 loss: 17.209951171875 acc: 0.30333333333333334\n",
      "New set of weights found, iteration: 1169 loss: 17.000714518229167 acc: 0.31\n",
      "New set of weights found, iteration: 1170 loss: 16.9085791015625 acc: 0.37666666666666665\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Random optimisation 2 , adjusting values in certain direction, revert if loss increase\n",
    "lowest_loss = 9999999  # some initial value\n",
    "best_layer1_weights = layer1.weights\n",
    "best_layer1_biases = layer1.biases\n",
    "best_layer2_weights = layer2.weights\n",
    "best_layer2_biases = layer2.biases\n",
    "\n",
    "for iteration in range(10000):\n",
    "\n",
    "    # Generate a new set of weights for iteration\n",
    "    layer1.weights += 0.05 * np.random.randn(2, 3)\n",
    "    layer1.biases += 0.05 * np.random.randn(1, 3)\n",
    "    layer2.weights += 0.05 * np.random.randn(3, 3)\n",
    "    layer2.biases += 0.05 * np.random.randn(1, 3)\n",
    "\n",
    "    # Make a forward pass of the training data through this layer\n",
    "    layer1.forward(X)\n",
    "    activation1.forward(layer1.output)\n",
    "    layer2.forward(activation1.output)\n",
    "    activation2.forward(layer2.output)\n",
    "    # Calculate loss (from activation output, softmax activation here) and accuracy\n",
    "    loss = loss_function.forward(activation2.output, y)\n",
    "    predictions = np.argmax(activation2.output, axis=1)  # calculate values along first axis\n",
    "    accuracy = np.mean(predictions==y)\n",
    "\n",
    "    # If loss is smaller - print and save weights and biases aside\n",
    "    if loss < lowest_loss:\n",
    "        print('New set of weights found, iteration:', iteration, 'loss:', loss, 'acc:', accuracy)\n",
    "        best_layer1_weights = layer1.weights\n",
    "        best_layer1_biases = layer1.biases\n",
    "        best_layer2_weights = layer2.weights\n",
    "        best_layer2_biases = layer2.biases\n",
    "        lowest_loss = loss\n",
    "    else: #Reversion\n",
    "        layer1.weights = best_layer1_weights\n",
    "        layer1.biases = best_layer1_biases\n",
    "        layer2.weights = best_layer2_weights\n",
    "        layer2.biases = best_layer2_biases\n",
    "#ENCOUNTER PROBLEM CONNECTED WITH JUPYTERLAB , METHOD IS NOT RELIABLE ANYWAY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = np.array([[1, 2, 3, 2.5], [2., 5., -1., 2], [-1.5, 2.7, 3.3, -0.8]])  # now we have 3 samples (feature sets) of data\n",
    "weights = np.array([[0.2, 0.8, -0.5, 1], # now we have 3 sets of weights - one set for each neuron\n",
    "                    [0.5, -0.91, 0.26, -0.5],\n",
    "                    [-0.26, -0.27, 0.17, 0.87]]).T\n",
    "biases = np.array([[2], [3], [0.5]]).T  # one bias for each neuron\n",
    "\n",
    "# Forward pass\n",
    "layer_outputs = np.dot(inputs, weights) + biases  # forward pass thru Dense layer\n",
    "relu_outputs = np.maximum(0, layer_outputs)  # forward pass thru ReLU activation\n",
    "\n",
    "# Let's optimize and test backpropagation here\n",
    "# ReLU activation\n",
    "relu_dvalues = np.ones(relu_outputs.shape) # simulates derivative with respect to input values from next layer passed to current layer during backpropagation\n",
    "relu_dvalues[layer_outputs <= 0] = 0\n",
    "drelu = relu_dvalues\n",
    "\n",
    "# Dense layer\n",
    "dinputs = np.dot(drelu, weights.T)  # dinputs - multiply by weights\n",
    "dweights = np.dot(inputs.T, drelu)  # dweights - multiply by inputs\n",
    "dbiases = np.sum(drelu, axis=0, keepdims=True)  # dbiases - sum values, do this over samples (first axis), keepdims as this by default will produce a plain list - we discussed this earlier\n",
    "\n",
    "# Update parameters\n",
    "weights += -0.001 * dweights\n",
    "biases += -0.001 * dbiases\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 0.360, loss: 1.099, lr: 0.0575\n",
      "epoch: 100, acc: 0.753, loss: 0.607, lr: 0.05749715382138749\n",
      "epoch: 200, acc: 0.787, loss: 0.479, lr: 0.057488558646061005\n",
      "epoch: 300, acc: 0.863, loss: 0.353, lr: 0.0574742170579969\n",
      "epoch: 400, acc: 0.893, loss: 0.293, lr: 0.05745413336430066\n",
      "epoch: 500, acc: 0.900, loss: 0.260, lr: 0.05742831359305091\n",
      "epoch: 600, acc: 0.920, loss: 0.230, lr: 0.05739676549028411\n",
      "epoch: 700, acc: 0.920, loss: 0.208, lr: 0.05735949851612153\n",
      "epoch: 800, acc: 0.930, loss: 0.201, lr: 0.05731652384004162\n",
      "epoch: 900, acc: 0.920, loss: 0.200, lr: 0.05726785433530062\n",
      "epoch: 1000, acc: 0.937, loss: 0.179, lr: 0.05721350457250595\n",
      "epoch: 1100, acc: 0.943, loss: 0.172, lr: 0.057153490812346115\n",
      "epoch: 1200, acc: 0.950, loss: 0.167, lr: 0.05708783099748289\n",
      "epoch: 1300, acc: 0.953, loss: 0.160, lr: 0.05701654474361081\n",
      "epoch: 1400, acc: 0.957, loss: 0.155, lr: 0.05693965332969104\n",
      "epoch: 1500, acc: 0.957, loss: 0.150, lr: 0.05685717968736526\n",
      "epoch: 1600, acc: 0.960, loss: 0.145, lr: 0.05676914838955814\n",
      "epoch: 1700, acc: 0.957, loss: 0.140, lr: 0.05667558563827575\n",
      "epoch: 1800, acc: 0.940, loss: 0.163, lr: 0.05657651925160783\n",
      "epoch: 1900, acc: 0.960, loss: 0.133, lr: 0.05647197864994457\n",
      "epoch: 2000, acc: 0.957, loss: 0.130, lr: 0.05636199484141552\n",
      "epoch: 2100, acc: 0.963, loss: 0.127, lr: 0.05624660040656211\n",
      "epoch: 2200, acc: 0.963, loss: 0.124, lr: 0.056125829482253836\n",
      "epoch: 2300, acc: 0.963, loss: 0.121, lr: 0.0559997177448593\n",
      "epoch: 2400, acc: 0.963, loss: 0.118, lr: 0.05586830239268352\n",
      "epoch: 2500, acc: 0.963, loss: 0.114, lr: 0.05573162212768421\n",
      "epoch: 2600, acc: 0.963, loss: 0.111, lr: 0.05558971713647895\n",
      "epoch: 2700, acc: 0.967, loss: 0.108, lr: 0.055442629070656384\n",
      "epoch: 2800, acc: 0.967, loss: 0.105, lr: 0.05529040102640576\n",
      "epoch: 2900, acc: 0.970, loss: 0.102, lr: 0.055133077523477216\n",
      "epoch: 3000, acc: 0.973, loss: 0.106, lr: 0.05497070448348897\n",
      "epoch: 3100, acc: 0.970, loss: 0.101, lr: 0.05480332920759486\n",
      "epoch: 3200, acc: 0.970, loss: 0.099, lr: 0.0546310003535278\n",
      "epoch: 3300, acc: 0.970, loss: 0.098, lr: 0.05445376791203501\n",
      "epoch: 3400, acc: 0.970, loss: 0.097, lr: 0.05427168318272092\n",
      "epoch: 3500, acc: 0.970, loss: 0.095, lr: 0.05408479874931414\n",
      "epoch: 3600, acc: 0.970, loss: 0.094, lr: 0.053893168454374266\n",
      "epoch: 3700, acc: 0.970, loss: 0.093, lr: 0.053696847373457236\n",
      "epoch: 3800, acc: 0.970, loss: 0.092, lr: 0.053495891788754996\n",
      "epoch: 3900, acc: 0.967, loss: 0.091, lr: 0.053290359162228046\n",
      "epoch: 4000, acc: 0.967, loss: 0.090, lr: 0.05308030810824858\n",
      "epoch: 4100, acc: 0.967, loss: 0.089, lr: 0.05286579836577227\n",
      "epoch: 4200, acc: 0.967, loss: 0.088, lr: 0.052646890770057186\n",
      "epoch: 4300, acc: 0.967, loss: 0.087, lr: 0.05242364722394871\n",
      "epoch: 4400, acc: 0.967, loss: 0.085, lr: 0.05219613066874968\n",
      "epoch: 4500, acc: 0.967, loss: 0.084, lr: 0.051964405054694185\n",
      "epoch: 4600, acc: 0.967, loss: 0.083, lr: 0.05172853531104512\n",
      "epoch: 4700, acc: 0.967, loss: 0.082, lr: 0.05148858731583416\n",
      "epoch: 4800, acc: 0.970, loss: 0.081, lr: 0.051244627865265006\n",
      "epoch: 4900, acc: 0.970, loss: 0.080, lr: 0.05099672464279867\n",
      "epoch: 5000, acc: 0.967, loss: 0.079, lr: 0.050744946187941495\n",
      "epoch: 5100, acc: 0.970, loss: 0.078, lr: 0.05048936186475566\n",
      "epoch: 5200, acc: 0.970, loss: 0.077, lr: 0.05023004183011235\n",
      "epoch: 5300, acc: 0.970, loss: 0.081, lr: 0.04996705700170821\n",
      "epoch: 5400, acc: 0.967, loss: 0.078, lr: 0.049700479025864754\n",
      "epoch: 5500, acc: 0.967, loss: 0.077, lr: 0.04943038024513185\n",
      "epoch: 5600, acc: 0.967, loss: 0.075, lr: 0.04915683366571511\n",
      "epoch: 5700, acc: 0.970, loss: 0.075, lr: 0.04887991292474815\n",
      "epoch: 5800, acc: 0.967, loss: 0.074, lr: 0.048599692257429626\n",
      "epoch: 5900, acc: 0.970, loss: 0.073, lr: 0.04831624646404558\n",
      "epoch: 6000, acc: 0.967, loss: 0.073, lr: 0.048029650876897874\n",
      "epoch: 6100, acc: 0.973, loss: 0.072, lr: 0.04773998132715866\n",
      "epoch: 6200, acc: 0.977, loss: 0.071, lr: 0.04744731411167093\n",
      "epoch: 6300, acc: 0.973, loss: 0.070, lr: 0.04715172595971584\n",
      "epoch: 6400, acc: 0.977, loss: 0.070, lr: 0.046853293999766794\n",
      "epoch: 6500, acc: 0.977, loss: 0.069, lr: 0.04655209572624976\n",
      "epoch: 6600, acc: 0.980, loss: 0.068, lr: 0.04624820896633035\n",
      "epoch: 6700, acc: 0.980, loss: 0.068, lr: 0.0459417118467466\n",
      "epoch: 6800, acc: 0.980, loss: 0.067, lr: 0.045632682760708115\n",
      "epoch: 6900, acc: 0.977, loss: 0.066, lr: 0.0453212003348793\n",
      "epoch: 7000, acc: 0.980, loss: 0.066, lr: 0.045007343396467496\n",
      "epoch: 7100, acc: 0.980, loss: 0.065, lr: 0.044691190940434077\n",
      "epoch: 7200, acc: 0.980, loss: 0.064, lr: 0.04437282209684748\n",
      "epoch: 7300, acc: 0.980, loss: 0.064, lr: 0.044052316098396604\n",
      "epoch: 7400, acc: 0.980, loss: 0.063, lr: 0.043729752248083044\n",
      "epoch: 7500, acc: 0.980, loss: 0.062, lr: 0.04340520988711025\n",
      "epoch: 7600, acc: 0.980, loss: 0.062, lr: 0.04307876836298711\n",
      "epoch: 7700, acc: 0.980, loss: 0.061, lr: 0.04275050699786355\n",
      "epoch: 7800, acc: 0.980, loss: 0.060, lr: 0.04242050505711567\n",
      "epoch: 7900, acc: 0.980, loss: 0.060, lr: 0.042088841718196685\n",
      "epoch: 8000, acc: 0.980, loss: 0.059, lr: 0.04175559603977091\n",
      "epoch: 8100, acc: 0.980, loss: 0.058, lr: 0.04142084693114665\n",
      "epoch: 8200, acc: 0.977, loss: 0.058, lr: 0.04108467312202396\n",
      "epoch: 8300, acc: 0.983, loss: 0.057, lr: 0.04074715313257311\n",
      "epoch: 8400, acc: 0.980, loss: 0.056, lr: 0.040408365243858754\n",
      "epoch: 8500, acc: 0.980, loss: 0.055, lr: 0.04006838746862444\n",
      "epoch: 8600, acc: 0.983, loss: 0.056, lr: 0.03972729752245274\n",
      "epoch: 8700, acc: 0.983, loss: 0.058, lr: 0.03938517279531407\n",
      "epoch: 8800, acc: 0.983, loss: 0.054, lr: 0.03904209032351884\n",
      "epoch: 8900, acc: 0.983, loss: 0.053, lr: 0.03869812676208572\n",
      "epoch: 9000, acc: 0.983, loss: 0.052, lr: 0.038353358357538996\n",
      "epoch: 9100, acc: 0.983, loss: 0.051, lr: 0.03800786092114778\n",
      "epoch: 9200, acc: 0.983, loss: 0.051, lr: 0.03766170980261899\n",
      "epoch: 9300, acc: 0.977, loss: 0.051, lr: 0.03731497986425555\n",
      "epoch: 9400, acc: 0.983, loss: 0.049, lr: 0.03696774545559145\n",
      "epoch: 9500, acc: 0.983, loss: 0.050, lr: 0.03662008038851448\n",
      "epoch: 9600, acc: 0.983, loss: 0.048, lr: 0.0362720579128865\n",
      "epoch: 9700, acc: 0.983, loss: 0.048, lr: 0.03592375069267149\n",
      "epoch: 9800, acc: 0.983, loss: 0.047, lr: 0.03557523078258122\n",
      "epoch: 9900, acc: 0.983, loss: 0.047, lr: 0.03522656960524691\n",
      "epoch: 10000, acc: 0.987, loss: 0.048, lr: 0.0348778379289257\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "# Our sample dataset\n",
    "def create_data(n, k):\n",
    "    X = np.zeros((n*k, 2))  # data matrix (each row = single example)\n",
    "    y = np.zeros(n*k, dtype='uint8')  # class labels\n",
    "    for j in range(k):\n",
    "        ix = range(n*j, n*(j+1))\n",
    "        r = np.linspace(0.0, 1, n)  # radius\n",
    "        t = np.linspace(j*4, (j+1)*4, n) + np.random.randn(n)*0.2  # theta\n",
    "        X[ix] = np.c_[r*np.sin(t*2.5), r*np.cos(t*2.5)]\n",
    "        y[ix] = j\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# Dense layer\n",
    "class Layer_Dense:\n",
    "\n",
    "    # Layer initialization\n",
    "    def __init__(self, inputs, neurons):\n",
    "        # Initialize weights and biases\n",
    "        self.weights = 0.01 * np.random.randn(inputs, neurons)\n",
    "        self.biases = np.zeros((1, neurons))\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "        # Calculate output values from input ones, weights and biases\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Gradients on parameters\n",
    "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
    "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
    "        # Gradient on values\n",
    "        self.dvalues = np.dot(dvalues, self.weights.T)\n",
    "\n",
    "\n",
    "# ReLU activation\n",
    "class Activation_ReLU:\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "        # Calculate output values from input ones\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Since we need to modify original variable, \n",
    "        # let's make a copy of values first\n",
    "        self.dvalues = dvalues.copy()\n",
    "\n",
    "        # Zero gradient where input values were negative \n",
    "        self.dvalues[self.inputs <= 0] = 0 \n",
    "\n",
    "\n",
    "# Softmax activation\n",
    "class Activation_Softmax:\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "\n",
    "        # get unnormalized probabilities\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "        # normalize them for each sample\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "\n",
    "        self.output = probabilities\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        self.dvalues = dvalues.copy()\n",
    "\n",
    "\n",
    "# Cross-entropy loss\n",
    "class Loss_CategoricalCrossentropy:\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, y_pred, y_true):\n",
    "\n",
    "        # Number of samples in a batch\n",
    "        samples = y_pred.shape[0]\n",
    "\n",
    "        # Probabilities for target values - only if categorical labels\n",
    "        if len(y_true.shape) == 1:\n",
    "            y_pred = y_pred[range(samples), y_true]\n",
    "\n",
    "        # Losses\n",
    "        negative_log_likelihoods = -np.log(y_pred)\n",
    "\n",
    "        # Mask values - only for one-hot encoded labels\n",
    "        if len(y_true.shape) == 2:\n",
    "            negative_log_likelihoods *= y_true\n",
    "\n",
    "        # Overall loss\n",
    "        data_loss = np.sum(negative_log_likelihoods) / samples\n",
    "        return data_loss\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues, y_true):\n",
    "\n",
    "        samples = dvalues.shape[0]\n",
    "\n",
    "        self.dvalues = dvalues.copy()  # Copy so we can safely modify\n",
    "        self.dvalues[range(samples), y_true] -= 1\n",
    "        self.dvalues = self.dvalues / samples\n",
    "class Optimizer_Adam:\n",
    "\n",
    "    # Initialize optimizer - set settings\n",
    "    def __init__(self, learning_rate=0.001, decay=0., epsilon=1e-7, beta_1=0.9, beta_2=0.999):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.epsilon = epsilon\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "\n",
    "    # Call once before any parameter updates\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.current_learning_rate * (1. / (1. + self.decay * self.iterations))\n",
    "\n",
    "    # Update parameters\n",
    "    def update_params(self, layer):\n",
    "\n",
    "        # If layer does not contain cache arrays,\n",
    "        # create them filled with zeros\n",
    "        if not hasattr(layer, 'weight_cache'):\n",
    "            layer.weight_momentums = np.zeros_like(layer.weights)\n",
    "            layer.weight_cache = np.zeros_like(layer.weights)\n",
    "            layer.bias_momentums = np.zeros_like(layer.biases)\n",
    "            layer.bias_cache = np.zeros_like(layer.biases)\n",
    "\n",
    "        # Update momentum  with current gradients\n",
    "        layer.weight_momentums = (self.beta_1 * layer.weight_momentums +\n",
    "                                 (1 - self.beta_1) * layer.dweights)\n",
    "        layer.bias_momentums = (self.beta_1 * layer.bias_momentums +\n",
    "                               (1 - self.beta_1) * layer.dbiases)\n",
    "        # Get corrected momentum\n",
    "        # self.iteration is 0 at first pass\n",
    "        # and we need to start with 1 here\n",
    "        weight_momentums_corrected = (layer.weight_momentums /\n",
    "            (1 - self.beta_1 ** (self.iterations + 1)))\n",
    "        bias_momentums_corrected = (layer.bias_momentums /\n",
    "            (1 - self.beta_1 ** (self.iterations + 1)))\n",
    "        # Update cache with squared current gradients\n",
    "        layer.weight_cache = (self.beta_2 * layer.weight_cache +\n",
    "            (1 - self.beta_2) * layer.dweights**2)\n",
    "        layer.bias_cache = (self.beta_2 * layer.bias_cache +\n",
    "            (1 - self.beta_2) * layer.dbiases**2)\n",
    "        # Get corrected cachebias\n",
    "        weight_cache_corrected = (layer.weight_cache /\n",
    "            (1 - self.beta_2 ** (self.iterations + 1)))\n",
    "        bias_cache_corrected = (layer.bias_cache /\n",
    "            (1 - self.beta_2 ** (self.iterations + 1)))\n",
    "\n",
    "        # Vanilla SGD parameter update + normalization with square rooted cache\n",
    "        layer.weights += (-self.current_learning_rate *\n",
    "                         weight_momentums_corrected /\n",
    "                         (np.sqrt(weight_cache_corrected) +\n",
    "                             self.epsilon))\n",
    "        layer.biases += (-self.current_learning_rate *\n",
    "                         bias_momentums_corrected /\n",
    "                         (np.sqrt(bias_cache_corrected) +\n",
    "                             self.epsilon))\n",
    "\n",
    "    # Call once after any parameter updates\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1\n",
    "\n",
    "\n",
    "# Create dataset\n",
    "X, y = create_data(100, 3)\n",
    "\n",
    "# Create Dense layer with 2 input features and 3 output values\n",
    "dense1 = Layer_Dense(2, 64)  # first dense layer, 2 inputs (each sample has 2 features), 3 outputs\n",
    "\n",
    "# Create ReLU activation (to be used with Dense layer):\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "# Create second Dense layer with 3 input features (as we take output of previous layer here) and 3 output values (output values)\n",
    "dense2 = Layer_Dense(64, 3)  # second dense layer, 3 inputs, 3 outputs\n",
    "\n",
    "# Create Softmax activation (to be used with Dense layer):\n",
    "activation2 = Activation_Softmax()\n",
    "\n",
    "# Create loss function\n",
    "loss_function = Loss_CategoricalCrossentropy()\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = Optimizer_Adam(learning_rate=0.0575, decay=1e-8)\n",
    "\n",
    "# Train in loop\n",
    "for epoch in range(10001):\n",
    "\n",
    "    # Make a forward pass of our training data thru this layer\n",
    "    dense1.forward(X)\n",
    "\n",
    "    # Make a forward pass thru activation function - we take output of previous layer here\n",
    "    activation1.forward(dense1.output)\n",
    "\n",
    "    # Make a forward pass thru second Dense layer - it takes outputs of activation function of first layer as inputs\n",
    "    dense2.forward(activation1.output)\n",
    "\n",
    "    # Make a forward pass thru activation function - we take output of previous layer here\n",
    "    activation2.forward(dense2.output)\n",
    "\n",
    "    # Calculate loss from output of activation2 so softmax activation\n",
    "    loss = loss_function.forward(activation2.output, y)\n",
    "\n",
    "    # Calculate accuracy from output of activation2 and targets\n",
    "    predictions = np.argmax(activation2.output, axis=1)  # calculate values along first axis\n",
    "    accuracy = np.mean(predictions==y)\n",
    "\n",
    "    if not epoch % 100:\n",
    "        print(f'epoch: {epoch}, acc: {accuracy:.3f}, loss: {loss:.3f}, lr: {optimizer.current_learning_rate}')\n",
    "\n",
    "    # Backward pass\n",
    "    loss_function.backward(activation2.output, y)\n",
    "    activation2.backward(loss_function.dvalues)\n",
    "    dense2.backward(activation2.dvalues)\n",
    "    activation1.backward(dense2.dvalues)\n",
    "    dense1.backward(activation1.dvalues)\n",
    "\n",
    "    # Update weights\n",
    "    optimizer.pre_update_params()\n",
    "    optimizer.update_params(dense1)\n",
    "    optimizer.update_params(dense2)\n",
    "    optimizer.post_update_params()\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['', '', 'malafya']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = 'If u give a shit you r : {0},{1},{2}'.format('python',a[1],a[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If u give a shit you r : python,,malafya'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['first','second','third']\n",
    "a =enumerate(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'first')\n",
      "(1, 'second')\n",
      "(2, 'third')\n"
     ]
    }
   ],
   "source": [
    "for i in a: \n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'enumerate' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-8bc71255a22e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'enumerate' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a\n",
    "answer = sorted(a.values())\n",
    "answer[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = '12123123'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = list(set(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerate(X):\n",
    "    for i in range(len(X)-1):\n",
    "        if X[i] == X[i+1]:\n",
    "            return False\n",
    "    return True\n",
    "def alternate(s):\n",
    "    st = list(set(s))\n",
    "    max_length = 0\n",
    "    for i in range(len(st)-1):\n",
    "        for b in range(i+1,len(st)):\n",
    "            local_list = [c for c in s if c==st[i] or c==st[b]]\n",
    "            print(local_list)\n",
    "            if numerate(local_list):\n",
    "                max_length = max(len(local_list),max_length)\n",
    "    return max_length\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(1+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendAndDelete(s, t, k):\n",
    "    if len(s)+len(t) <=k:\n",
    "        return 'Yes'\n",
    "    if len(s)<len(t) and s == t[:len(s)]:\n",
    "        if len(t)-len(s)==k:\n",
    "            return 'Yes'\n",
    "        if len(s)+len(t)<=k:\n",
    "            return 'Yes'\n",
    "        return 'No'\n",
    "        \n",
    "    for i in range (len(t)):\n",
    "        if s[:len(t)-i] == t[:len(t)-i]:\n",
    "            if k>=(len(s)-(len(t)+i))+i:\n",
    "                return 'Yes'\n",
    "            return 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "appendAndDelete('asdfqwertyuighjkzxcvasdfqwertyuighjkzxcvasdfqwertyuighjkzxcvasdfqwertyuighjkzxcvasdfqwertyuighjkzxcv','bsdfqwertyuighjkzxcvasdfqwertyuighjkzxcvasdfqwertyuighjkzxcvasdfqwertyuighjkzxcvasdfqwertyuighjkzxcv',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continue_list(prev_number,difference,counter,st,diff):\n",
    "    if counter == 1:\n",
    "        st.add(prev_number+difference)\n",
    "        return\n",
    "    for i in range(2):\n",
    "        continue_list(prev_number+difference,diff[i],counter-1,st,diff)\n",
    "    return \n",
    "def stones(n, a, b):\n",
    "    answer = set()\n",
    "    diff = [a,b]\n",
    "    continue_list(0,a,n-1,answer,diff)\n",
    "    continue_list(0,b,n-1,answer,diff)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4, 5, 6}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stones(2,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
